{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "from matplotlib.lines import Line2D\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from utils import train, compute_accuracy\n",
    "\n",
    "seed = 265\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Load Vocab, Embedding and Texts ----------------------------\n",
    "PATH_GENERATED = './generated/'\n",
    "\n",
    "vocab     = torch.load(PATH_GENERATED + 'vocabulary.pt', map_location=torch.device(device))\n",
    "embedding = torch.load(PATH_GENERATED + 'embedding.pt', map_location=torch.device(device))\n",
    "(VOCAB_SIZE, embedding_dim) = embedding.weight.shape  \n",
    "\n",
    "words_train = torch.load(PATH_GENERATED + \"words_train.pt\", map_location=torch.device(device))\n",
    "words_val   = torch.load(PATH_GENERATED + \"words_val.pt\", map_location=torch.device(device))\n",
    "words_test  = torch.load(PATH_GENERATED + \"words_test.pt\", map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Datasets ----------------------------\n",
    "CONTEXT_SIZE = 10\n",
    "not_words = [',', '.', '(', ')', '?', '!', '<unk>']\n",
    "not_words_idx = vocab.lookup_indices(not_words)\n",
    "\n",
    "def create_dataset(text, vocab, context_size=CONTEXT_SIZE, dataset_limit=50):\n",
    "    \"\"\"\n",
    "    Create targets-contexts pairs where the targets are valid words from the given text up to dataset_limit.\n",
    "    \"\"\"\n",
    "    txt = [vocab[w] for w in text]\n",
    "    n_text = len(text)\n",
    "    word_bank = {}\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size):\n",
    "        \n",
    "        t = txt[i + context_size]\n",
    "        w = vocab.lookup_token(t)\n",
    "\n",
    "        if w in not_words: continue\n",
    "        if w not in word_bank: word_bank[w] = 0\n",
    "        if word_bank[w] > dataset_limit: continue\n",
    "        word_bank[w] += 1\n",
    "\n",
    "        c = txt[i:i + context_size]\n",
    "        \n",
    "        targets.append(t) \n",
    "        contexts.append(torch.tensor(c).to(device=device))\n",
    "            \n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets).to(device=device)\n",
    "    return TensorDataset(contexts, targets)\n",
    "\n",
    "def load_dataset(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if its already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isfile(PATH_GENERATED + fname):\n",
    "        dataset = torch.load(PATH_GENERATED + fname, map_location=torch.device(device))\n",
    "    else:\n",
    "        dataset = create_dataset(words, vocab)\n",
    "        torch.save(dataset, PATH_GENERATED + fname)\n",
    "    return dataset\n",
    "\n",
    "data_train_gen = load_dataset(words_train, vocab, \"gen_data_train.pt\")\n",
    "data_val_gen   = load_dataset(words_val, vocab, \"gen_data_val.pt\")\n",
    "data_test_gen  = load_dataset(words_test, vocab, \"gen_data_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Balance the training set ----------------------------\n",
    "def count_freqs(words, vocab):\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "def calculate_word_weights(freqs):\n",
    "    \"\"\"\n",
    "    Calculate the weight of each word so that the loss function can weigh \n",
    "    frequent words less and unfrequent words more.\n",
    "    \"\"\"\n",
    "    total_words = sum(freqs)\n",
    "    word_weights = [total_words / (len(freqs)* freq) for freq in freqs]\n",
    "    word_weights = torch.tensor(word_weights, dtype=torch.float).to(device=device)\n",
    "    return word_weights\n",
    "\n",
    "target_words_idx = data_train_gen[:][1].tolist()\n",
    "target_words = [vocab.lookup_token(i) for i in target_words_idx]\n",
    "freqs = count_freqs(target_words, vocab)\n",
    "word_weigts = calculate_word_weights(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- RNN hyper-parameters ----------------------- \n",
    "lrs = [0.01, 0.001]\n",
    "rnn_hparams = [{\n",
    "    'lr': lr,\n",
    "} for lr in lrs]\n",
    "\n",
    "# ---------------- Dataloaders -----------------------\n",
    "train_loader = DataLoader(data_train_gen, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(data_val_gen, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(data_test_gen, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- RNN model ----------------------------\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embedding_dim)\n",
    "        self.embedding.load_state_dict(embedding.state_dict())\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=VOCAB_SIZE, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        return h_n[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Train all models ----------------------------\n",
    "def train_all_models():\n",
    "    models = []\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "    params = []\n",
    "    print(\"Now training a RNN model\")\n",
    "    for param in rnn_hparams:\n",
    "        print(f\"Training using parameters: {param}\")\n",
    "        torch.manual_seed(seed)\n",
    "        model = RNN(embedding)\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=word_weigts)\n",
    "        optimizer = optim.Adam(model.parameters(), **param)\n",
    "        n_epochs = 5\n",
    "        \n",
    "        loss = train(n_epochs, optimizer, model, loss_fn, train_loader, device, yield_tokens=not_words_idx)\n",
    "        accuracy = compute_accuracy(model, val_loader, device)\n",
    "\n",
    "        models.append(model)\n",
    "        train_losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "        params.append(param)\n",
    "        print()\n",
    "    return models, train_losses, accuracies, params\n",
    "\n",
    "# ----------------------- Select the best model ----------------------------\n",
    "def select_best_model(models, accuracies, params):\n",
    "    best_idx = accuracies.index(max(accuracies))\n",
    "    best_model = models[best_idx]\n",
    "    best_param = params[best_idx]\n",
    "\n",
    "    # ----------------------- Retrain the best model ----------------------------\n",
    "    print(f\"Training using parameters: {best_param}\")\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=word_weigts)\n",
    "    optimizer = optim.Adam(best_model.parameters(), **best_param)\n",
    "    n_epochs = 20\n",
    "\n",
    "    loss = train(n_epochs, optimizer, best_model, loss_fn, train_loader, device, yield_tokens=not_words_idx)\n",
    "    accuracy = compute_accuracy(best_model, test_loader, device)\n",
    "\n",
    "    return best_model, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the best model on the test set is 0.01\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Best Model -------------------------------\n",
    "if os.path.isfile(PATH_GENERATED + 'best_model_generation.pt'):\n",
    "    best_model = torch.load(PATH_GENERATED + 'best_model_generation.pt', map_location=torch.device(device))\n",
    "    accuracy = torch.load(PATH_GENERATED + 'best_model_generation_accuracy.pt', map_location=torch.device(device))\n",
    "else:\n",
    "    models, train_losses, val_accs, params = train_all_models()\n",
    "    best_model, best_model_loss, accuracy = select_best_model(models, val_accs, params)\n",
    "    torch.save(best_model, PATH_GENERATED + 'best_model_generation.pt')\n",
    "    torch.save(accuracy, PATH_GENERATED + 'best_model_generation_accuracy.pt')\n",
    "\n",
    "print(f\"The accuracy of the best model on the test set is {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Predicting sentence with Beam Search -------------------------------\n",
    "def beam_search(input, n_output, model):\n",
    "    \"\"\"\n",
    "    Return the n_output best predictions from the model given input.\n",
    "    \"\"\"\n",
    "    input = torch.tensor(vocab.lookup_indices(input))\n",
    "    output = model(input)\n",
    "    \n",
    "    out = torch.topk(output, n_output)\n",
    "    return out\n",
    "\n",
    "def predict_sentence(input, beam_width, n_predict, model):\n",
    "    \"\"\"\n",
    "    Predicts the n_predict next words of the model given input using beam search with given beam width.\n",
    "    \"\"\"\n",
    "    input = [input.split()]\n",
    "    for _ in range(n_predict):\n",
    "        values = torch.empty(0)\n",
    "        indices = torch.empty(0)\n",
    "        sentences = []\n",
    "        for sentence in input:\n",
    "            prediction = beam_search(sentence, beam_width, model)\n",
    "            values = torch.cat((values, prediction.values))\n",
    "            indices = torch.cat((indices, prediction.indices))\n",
    "            sentences.append(sentence)\n",
    "\n",
    "        new_input = []\n",
    "        best_predictions = torch.topk(values, beam_width)\n",
    "        origin_sen = [int(idx/beam_width) for idx in best_predictions.indices]\n",
    "        words = [vocab.lookup_token(indices[idx]) for idx in best_predictions.indices]\n",
    "        for i, word in enumerate(words):\n",
    "            new_sentence = sentences[origin_sen[i]].copy()\n",
    "            new_sentence.append(word)\n",
    "            new_input.append(new_sentence)\n",
    "        input = new_input\n",
    "    return \" \".join(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentence generation by guessing the next word with beam width: 5\n",
      "\n",
      "humans are gentlemen\n",
      "cats are gentlemen\n",
      "dogs are edge\n",
      "birds are torn\n",
      "horses are enemy\n",
      "\n",
      "\n",
      "\n",
      "Testing sentence generation by guessing the next two words with beam width: 10\n",
      "\n",
      "the tall mountain is forty attack\n",
      "todays weather is sown south\n",
      "my old house is forty mother\n",
      "the language model is locked strength\n",
      "\n",
      "\n",
      "\n",
      "Testing sentence generation by guessing the next ten words with beam width: 10\n",
      "\n",
      "what scarcely t do . exclaimed exclaimed exclaimed ye t ye\n",
      "no slight influence occurred thank horror required importance required what o\n",
      "yes eastward bring farther late sown sown south south south south\n",
      "husband t re apart . sown sown sown sown ft pieces\n",
      "wife addressed sorry moved kingdom other sorry sorry sorry sorry seat\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Predicting a few sentences -------------------------------\n",
    "print(f\"Testing sentence generation by guessing the next word with beam width: 5\\n\")\n",
    "print(predict_sentence(\"humans are\", 5, 1, best_model))\n",
    "print(predict_sentence(\"cats are\", 5, 1, best_model))\n",
    "print(predict_sentence(\"dogs are\", 5, 1, best_model))\n",
    "print(predict_sentence(\"birds are\", 5, 1, best_model))\n",
    "print(predict_sentence(\"horses are\", 5, 1, best_model))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"Testing sentence generation by guessing the next two words with beam width: 10\\n\")\n",
    "print(predict_sentence(\"the tall mountain is\", 10, 2, best_model))\n",
    "print(predict_sentence(\"todays weather is\", 10, 2, best_model))\n",
    "print(predict_sentence(\"my old house is\", 10, 2, best_model))\n",
    "print(predict_sentence(\"the language model is\", 10, 2, best_model))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"Testing sentence generation by guessing the next ten words with beam width: 10\\n\")\n",
    "print(predict_sentence(\"what\", 10, 10, best_model))\n",
    "print(predict_sentence(\"no\", 10, 10, best_model))\n",
    "print(predict_sentence(\"yes\", 10, 10, best_model))\n",
    "print(predict_sentence(\"husband\", 10, 10, best_model))\n",
    "print(predict_sentence(\"wife\", 10, 10, best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
