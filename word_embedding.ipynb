{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import re\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from datetime import datetime\n",
    "\n",
    "seed = 265\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = get_tokenizer('basic_english')\n",
    "PATH_GENERATED = './generated/'\n",
    "MIN_FREQ = 100\n",
    "\n",
    "def read_files(datapath='./data_train/'):\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith('.txt')]\n",
    "\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            texts += f.readlines()\n",
    "    return texts\n",
    "\n",
    "def tokenize(texts, tokenizer=TOKENIZER):\n",
    "    tokenized_text = []\n",
    "    for text in texts:\n",
    "        tokenized_text += tokenizer(text)\n",
    "    return tokenized_text\n",
    "\n",
    "def yield_tokens(texts, tokenizer=TOKENIZER):\n",
    "    \"\"\"\n",
    "    Remove yield tokens from the text before tokenizing\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove words with digits, upper case, and multiple space \n",
    "    no_digits = '\\w*[0-9]+\\w*'\n",
    "    no_names = '\\w*[A-Z]+\\w*'\n",
    "    no_spaces = '\\s+'\n",
    "\n",
    "    for text in texts:\n",
    "        text = re.sub(no_digits, ' ', text)\n",
    "        text = re.sub(no_names, ' ', text)\n",
    "        text = re.sub(no_spaces, ' ', text)\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def count_freqs(words, vocab):\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "def create_vocabulary(lines, min_freq=MIN_FREQ):\n",
    "    \"\"\"\n",
    "    Create a vocabulary (list of known tokens) from a list of strings\n",
    "    \"\"\"\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"])\n",
    "    vocab.append_token(\"i\")  # Upper case words like 'I' were removed so we should add it back again.\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Tokenize texts -------------------------------\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + \"words_train.pt\"):\n",
    "    words_train = torch.load(PATH_GENERATED + \"words_train.pt\")\n",
    "    words_val   = torch.load(PATH_GENERATED + \"words_val.pt\")\n",
    "    words_test  = torch.load(PATH_GENERATED + \"words_test.pt\")\n",
    "else:\n",
    "    lines_books_train = read_files('./data_train/')\n",
    "    lines_books_val   = read_files('./data_val/')\n",
    "    lines_books_test  = read_files('./data_test/')\n",
    "\n",
    "    words_train = tokenize(lines_books_train)\n",
    "    words_val   = tokenize(lines_books_val)\n",
    "    words_test  = tokenize(lines_books_test)\n",
    "    \n",
    "    torch.save(words_train, PATH_GENERATED + \"words_train.pt\")\n",
    "    torch.save(words_val, PATH_GENERATED + \"words_val.pt\")\n",
    "    torch.save(words_test, PATH_GENERATED + \"words_test.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Create vocabulary ----------------------------\n",
    "\n",
    "VOCAB_FNAME = \"vocabulary.pt\"\n",
    "if os.path.isfile(PATH_GENERATED + VOCAB_FNAME):\n",
    "    vocab = torch.load(PATH_GENERATED + VOCAB_FNAME)\n",
    "else:\n",
    "    vocab = create_vocabulary(lines_books_train, min_freq=MIN_FREQ)\n",
    "    torch.save(vocab, PATH_GENERATED + VOCAB_FNAME)\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------------ Quick analysis ------------------------------\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "freqs = count_freqs(words_train, vocab)\n",
    "occurences = [(f.item(), w) for (f, w) in zip(freqs, vocab.lookup_tokens(range(VOCAB_SIZE)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Total number of words in the validation dataset:    49526\n",
      "Total number of words in the test dataset:          124152\n",
      "Number of distinct words in the training dataset:   52105\n",
      "Number of distinct words kept (vocabulary size):    1880\n",
      "The 10 most occuring words:\n",
      " [(433907, '<unk>'), (182537, ','), (151278, 'the'), (123727, '.'), (82289, 'and'), (65661, 'of'), (62763, 'to'), (49230, 'a'), (41477, 'in'), (31052, 'that')]\n"
     ]
    }
   ],
   "source": [
    "n_print = 10\n",
    "print(\"Total number of words in the training dataset:     \", len(words_train))\n",
    "print(\"Total number of words in the validation dataset:   \", len(words_val))\n",
    "print(\"Total number of words in the test dataset:         \", len(words_test))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(words_train)))\n",
    "print(\"Number of distinct words kept (vocabulary size):   \", VOCAB_SIZE)\n",
    "\n",
    "print(f\"The {n_print} most occuring words:\\n {occurences[:n_print]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "\n",
    "# ---------------- Define context / target pairs -----------------------\n",
    "def create_dataset(text, vocab, context_size=CONTEXT_SIZE):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset of context / target pairs from a text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform each word to its index in the vocabulary.\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    n_text = len(text)\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size):\n",
    "        \n",
    "        t = txt[i + context_size]\n",
    "        c = txt[i:i + context_size]\n",
    "        \n",
    "        targets.append(t) \n",
    "        contexts.append(torch.tensor(c).to(device=device))\n",
    "            \n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets).to(device=device)\n",
    "    return TensorDataset(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isfile(PATH_GENERATED + fname):\n",
    "        dataset = torch.load(PATH_GENERATED + fname)\n",
    "    else:\n",
    "        dataset = create_dataset(words, vocab)\n",
    "        torch.save(dataset, PATH_GENERATED + fname)\n",
    "    return dataset\n",
    "\n",
    "data_train = load_dataset(words_train, vocab, \"data_train.pt\")\n",
    "data_val   = load_dataset(words_val, vocab, \"data_val.pt\")\n",
    "data_test  = load_dataset(words_test, vocab, \"data_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, context_size=CONTEXT_SIZE):\n",
    "        super().__init__()\n",
    "        \n",
    "        (vocab_size, embedding_dim) = embedding.weight.shape\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim*context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = F.relu(self.fc1(torch.flatten(out, 1)))        \n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader, device=None):\n",
    "\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        loss_train = 0.0\n",
    "        for contexts, targets in train_loader:\n",
    "\n",
    "            contexts = contexts.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            outputs = model(contexts)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.5f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader, device=None):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for contexts, targets in loader:\n",
    "            contexts = contexts.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            outputs = model(contexts)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += len(targets)\n",
    "            correct += int((predicted == targets).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are testing 6 different hyper parameters.\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "embedding_dims = [10, 16]\n",
    "\n",
    "hparams = [{\n",
    "    'batch_size': bs,\n",
    "    'embedding_dim': em\n",
    " } for bs in batch_sizes for em in embedding_dims]\n",
    "\n",
    "print(f\"We are testing {len(hparams)} different hyper parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT RUN I HAVE SAVED THE TRAINED MODELS IN GENERATED\n",
    "models = []\n",
    "embeddings = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for param in hparams:\n",
    "    print(f'Now training with parameters {param}')\n",
    "    train_loader = DataLoader(data_train, batch_size=param['batch_size'], shuffle=True)\n",
    "    val_loader   = DataLoader(data_val, batch_size=param['batch_size'], shuffle=True)\n",
    "\n",
    "    embedding = nn.Embedding(VOCAB_SIZE, param['embedding_dim'])\n",
    "    torch.manual_seed(seed)\n",
    "    model = Word2Vec(embedding).to(device=device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    n_epochs=3\n",
    "    train(n_epochs, optimizer, model, loss_fn, train_loader)\n",
    "\n",
    "    models.append(model)\n",
    "    embeddings.append(embedding)\n",
    "    train_acc.append(compute_accuracy(model, train_loader))\n",
    "    val_acc.append(compute_accuracy(model, val_loader))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:59:16.270479  |  Epoch 1  |  Training loss 4.28919\n",
      "17:04:15.352456  |  Epoch 5  |  Training loss 3.87675\n",
      "17:11:14.967903  |  Epoch 10  |  Training loss 3.81888\n",
      "Training Accuracy:     0.2438\n",
      "Validation Accuracy:   0.2309\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "MODEL_FNAME = \"model.pt\"\n",
    "EMBEDDING_DIM = 16\n",
    "\n",
    "# Load the pretrained embedding \n",
    "if os.path.isfile(\"embedding.pt\"):\n",
    "    embedding = torch.load(\"embedding.pt\").to(device=device)\n",
    "else:\n",
    "    embedding = nn.Embedding(len(vocab), EMBEDDING_DIM)\n",
    "    torch.save(embedding, \"embedding.pt\")\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(data_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(data_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = Word2Vec(embedding)\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + MODEL_FNAME):\n",
    "    model = torch.load(PATH_GENERATED + MODEL_FNAME)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    n_epochs=10\n",
    "\n",
    "    train(n_epochs, optimizer, model, loss_fn, train_loader)\n",
    "    torch.save(model.to(device=\"cpu\"), PATH_GENERATED + MODEL_FNAME)\n",
    "\n",
    "acc_train = compute_accuracy(model, train_loader)\n",
    "acc_val = compute_accuracy(model, val_loader)\n",
    "print(\"Training Accuracy:     %.4f\" %acc_train)\n",
    "print(\"Validation Accuracy:   %.4f\" %acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7452, -1.4874,  0.5123,  1.3052,  0.2934,  0.5553, -0.8712, -2.1692,\n",
       "        -0.2182, -0.2197,  1.8711,  0.8342, -1.7075,  0.7678,  1.1717,  1.7013])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data[vocab['the']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor([ 1.2513, -1.4227,  0.1993,  1.1488,  0.1734,  0.2339, -0.5957, -1.4216,\n",
    "        -0.2747,  0.6735,  1.7830,  0.4373, -2.4252,  0.7154,  1.1046,  1.4459])\n",
    "\n",
    "tensor([ 0.4724, -2.2209, -0.5557,  1.0608,  0.1002,  0.4285, -0.7487, -2.3987,\n",
    "        -0.1100,  0.7012,  1.6068, -0.0888, -2.1806,  0.5736,  0.3631,  1.3329])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
