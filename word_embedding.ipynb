{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import re\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "seed = 265\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = get_tokenizer('basic_english')\n",
    "PATH_GENERATED = './generated/'\n",
    "MIN_FREQ = 100\n",
    "\n",
    "def read_files(datapath='./data_train/'):\n",
    "    files = os.listdir(datapath)\n",
    "    files = [datapath + f for f in files if f.endswith('.txt')]\n",
    "\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            texts += f.readlines()\n",
    "    return texts\n",
    "\n",
    "def tokenize(texts, tokenizer=TOKENIZER):\n",
    "    tokenized_text = []\n",
    "    for text in texts:\n",
    "        tokenized_text += tokenizer(text)\n",
    "    return tokenized_text\n",
    "\n",
    "def yield_tokens(texts, tokenizer=TOKENIZER):\n",
    "    # Match any word containing digit\n",
    "    no_digits = '\\w*[0-9]+\\w*'\n",
    "    # Match word containing a uppercase \n",
    "    no_names = '\\w*[A-Z]+\\w*'\n",
    "    # Match any sequence containing more than one space\n",
    "    no_spaces = '\\s+'\n",
    "\n",
    "    for text in texts:\n",
    "        text = re.sub(no_digits, ' ', text)\n",
    "        text = re.sub(no_names, ' ', text)\n",
    "        text = re.sub(no_spaces, ' ', text)\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def count_freqs(words, vocab):\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs\n",
    "\n",
    "def create_vocabulary(lines, min_freq=MIN_FREQ):\n",
    "    \"\"\"\n",
    "    Create a vocabulary (list of known tokens) from a list of strings\n",
    "    \"\"\"\n",
    "    # vocab contains the vocabulary found in the data, associating an index to each word\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"])\n",
    "    # Since we removed all words with an uppercase when building the vocabulary, we skipped the word \"I\"\n",
    "    vocab.append_token(\"i\")\n",
    "    # Value of default index. This index will be returned when OOV (Out Of Vocabulary) token is queried.\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the training dataset:      2684706\n",
      "Total number of words in the validation dataset:    49526\n",
      "Total number of words in the test dataset:          124152\n",
      "Number of distinct words in the training dataset:   52105\n",
      "Number of distinct words kept (vocabulary size):    1880\n",
      "occurences:\n",
      " [(433907, '<unk>'), (182537, ','), (151278, 'the'), (123727, '.'), (82289, 'and'), (65661, 'of'), (62763, 'to'), (49230, 'a'), (41477, 'in'), (31052, 'that'), (37167, 'he'), (29046, 'was'), (26508, 'his'), (26354, 'it'), (20862, 'with'), (20159, 'had'), (19965, 'is'), (15692, 'not'), (16593, 'as'), (15705, 'on'), (14464, 'him'), (15317, 'for'), (15838, 'at'), (15952, 'you'), (13255, 'be'), (12698, 'her'), (12798, 's'), (11924, 'which'), (11808, '!'), (11740, 'all'), (10338, '?'), (10205, 'have'), (10405, 'from'), (13251, 'but'), (11464, 'this'), (9439, 'by'), (11496, 'they'), (8797, 'said'), (8800, 'are'), (11055, 'she'), (9537, 'one'), (8219, 'were'), (8564, 'who'), (8345, 'so'), (9409, 'there'), (7072, 'or'), (6575, 'me'), (6478, 'them'), (6429, 'an'), (6868, 'my'), (5849, 'will'), (5692, 'man'), (7485, 'we'), (5641, 'up'), (5769, 'their'), (5510, 'out'), (5446, 'been'), (7638, 'when'), (6616, 'no'), (5164, 'would'), (7378, 'what'), (4643, 'into'), (5716, 'if'), (4257, 'more'), (4107, 'very'), (3956, 'could'), (3981, 'did'), (3834, 'men'), (3817, 'has'), (4231, 'do'), (6231, 'then'), (4105, 'some'), (7038, 'king'), (3679, 'other'), (3585, 'time'), (3617, 'about'), (3563, 'should'), (3480, 'went'), (3458, 'himself'), (3381, 'came'), (4406, 'now'), (3615, 'only'), (3551, 'your'), (3306, 'like'), (3406, 'two'), (3285, 'little'), (3193, 'before'), (3009, 'over'), (2975, 'made'), (2947, 'than'), (3011, 'see'), (3092, 'may'), (2844, 'down'), (2857, 'old'), (2748, 'us'), (2702, 'know'), (2831, 'can'), (2934, 'good'), (3070, 'where'), (2711, 't'), (2604, '('), (2604, ')'), (2605, 'must'), (2712, 'great'), (2744, 'our'), (2647, 'people'), (2746, 'go'), (2620, 'again'), (2818, 'come'), (2475, 'its'), (2897, 'these'), (3020, 'after'), (2339, 'any'), (2388, 'without'), (2287, 'day'), (2301, 'upon'), (2249, 'eyes'), (1057, 'â€”'), (2311, 'first'), (2224, 'way'), (2205, 'back'), (2171, 'away'), (2169, 'am'), (2142, 'same'), (2277, 'those'), (2125, 'thought'), (2996, 'well'), (2141, 'say'), (2109, 'took'), (2246, 'such'), (2130, 'long'), (2046, 'much'), (1980, 'hand'), (2053, 'still'), (1924, 'face'), (2708, 'how'), (1982, 'through'), (2372, 'here'), (1904, 'head'), (336, '-'), (2128, 'nothing'), (2040, 'many'), (1918, 'shall'), (1981, 'even'), (1855, 'off'), (2061, 'just'), (1754, 'own'), (1752, 'left'), (1738, 'saw'), (1769, 'life'), (1729, 'house'), (1683, 'also'), (1668, 'room'), (1651, 'heard'), (1678, 'too'), (1678, 'being'), (1706, 'make'), (1786, 'never'), (1787, 'take'), (1728, 'once'), (1635, 'night'), (1732, 'each'), (1637, 'most'), (1567, 'door'), (1567, 'seemed'), (1635, 'under'), (1615, 'place'), (1582, 'last'), (1543, 'right'), (1676, 'another'), (1494, 'whole'), (1476, 'asked'), (1462, 'began'), (1620, 'every'), (1504, 'something'), (1438, 'called'), (1473, 'young'), (1415, 'moment'), (1429, 'against'), (1392, 'looked'), (1450, 'get'), (1437, 'things'), (1390, 'might'), (1413, 'think'), (1463, 'three'), (1365, 'told'), (1359, 'felt'), (1621, 'father'), (1338, 'found'), (1357, 'always'), (1291, 'got'), (1311, 'set'), (1307, 'put'), (1840, 'let'), (1265, 'side'), (1242, 'gave'), (1226, 'seen'), (1227, 'round'), (1207, 'turned'), (1296, 'give'), (1216, 'whom'), (1208, 'country'), (1363, 'look'), (1305, 'though'), (1269, 'both'), (1431, 'while'), (1232, 'between'), (1183, 'going'), (1165, 'done'), (1258, 'tell'), (1157, 'woman'), (1222, 'because'), (1272, 'having'), (1109, 'taken'), (1120, 'army'), (1191, 'yet'), (1087, 'says'), (1105, 'light'), (1076, 'knew'), (1145, 'soon'), (1112, 'plants'), (1063, 'few'), (1051, 'part'), (1065, 'son'), (1066, 'others'), (1031, 'years'), (1028, 'voice'), (1020, 'hands'), (1069, 'love'), (1027, 'large'), (1013, 'morning'), (1022, 'end'), (997, 'themselves'), (1043, 'quite'), (995, 'words'), (982, 'stood'), (1033, 'behind'), (1209, 'thing'), (956, 'replied'), (1005, 'battle'), (1027, 'white'), (958, 'along'), (959, 'far'), (946, 'together'), (964, 'water'), (932, 'feet'), (930, 'ground'), (931, 'brought'), (935, 'home'), (923, 'anything'), (930, 'small'), (1047, 'everything'), (1162, 'don'), (917, 'mind'), (893, 'longer'), (889, 'name'), (911, 'already'), (955, 'does'), (886, 'find'), (892, 'wife'), (881, 'fell'), (876, 'word'), (904, 'order'), (963, 'death'), (864, 'matter'), (1046, 'mother'), (857, 'passed'), (856, 'herself'), (871, 'open'), (880, 'near'), (857, 'lay'), (839, 'll'), (842, 'child'), (838, 'sat'), (834, 'best'), (857, 'land'), (837, 'work'), (827, 'remained'), (826, 'bed'), (913, 'among'), (839, 'better'), (823, 'heart'), (822, 'alone'), (824, 'evening'), (878, 'dear'), (814, 'full'), (819, 'de'), (803, 'days'), (797, 'air'), (790, 'sent'), (846, 'poor'), (797, 'friend'), (880, 'new'), (766, 'front'), (860, 'since'), (758, 'sort'), (813, 'four'), (745, 'want'), (762, 'almost'), (742, 'given'), (741, 'table'), (742, 'became'), (747, 'dead'), (723, 'held'), (725, 'cannot'), (742, 'fire'), (719, 'ran'), (733, 'ever'), (763, 'nor'), (709, 'myself'), (765, 'towards'), (784, 'black'), (704, 'case'), (864, 'thou'), (698, 'cried'), (702, 'understand'), (714, 'looking'), (732, 'fall'), (807, 'suddenly'), (684, 'become'), (679, 'answered'), (683, 'ready'), (697, 'until'), (668, 'returned'), (704, 'leave'), (679, 'winter'), (672, 'gone'), (666, 'world'), (693, 'cut'), (662, 'used'), (771, 'general'), (679, 'often'), (655, 'daughter'), (660, 'power'), (651, 'soul'), (1308, 'why'), (643, 'entered'), (826, 'however'), (641, 'itself'), (641, 'possible'), (710, 'war'), (658, 'coming'), (642, 'arms'), (638, 'smile'), (661, 'true'), (635, 'window'), (670, 'half'), (658, 'whose'), (637, 'saying'), (638, 'point'), (635, 'less'), (649, 'rather'), (637, 'enough'), (629, 'laid'), (641, 'speak'), (646, 'certain'), (615, 'earth'), (1311, 'earl'), (607, 'fact'), (609, 'received'), (600, 'hour'), (652, 'red'), (615, 'garden'), (631, 'above'), (599, 'ships'), (595, 'hundred'), (587, 'opened'), (587, 'spoke'), (588, 'girl'), (585, 'lost'), (585, 'continued'), (591, 'ship'), (595, 'trees'), (603, 'horse'), (598, 'around'), (577, 'money'), (570, 'body'), (591, 'brother'), (573, 'hear'), (618, 'keep'), (578, 'spring'), (570, 'town'), (580, 'second'), (581, 'use'), (561, 'hair'), (559, 'rest'), (559, 'cold'), (569, 'terrible'), (565, 'close'), (557, 'course'), (566, 'high'), (564, 'husband'), (553, 'added'), (563, 'killed'), (555, 'met'), (573, 'road'), (665, 'sometimes'), (564, 'sound'), (559, 'children'), (564, 'within'), (590, 'whether'), (558, 'help'), (542, 'followed'), (545, 'making'), (716, 'thus'), (542, 'year'), (582, 'five'), (578, 'flowers'), (537, 'kept'), (713, 'o'), (545, 'taking'), (546, 'turn'), (536, 'present'), (528, 've'), (529, 'yourself'), (605, 'early'), (613, 'next'), (529, 'times'), (533, 'dark'), (546, 'force'), (523, 'necessary'), (525, 'officer'), (520, 'able'), (526, 'sleep'), (540, 'till'), (523, 'happened'), (533, 'either'), (525, 'short'), (511, 'wish'), (507, 'placed'), (604, 'street'), (512, 'fear'), (506, 'known'), (502, 'need'), (525, 'rose'), (502, 'wanted'), (528, 'fine'), (526, 'letter'), (520, 'ask'), (999, 'count'), (512, 'happy'), (497, 'question'), (494, 'wall'), (494, 'idea'), (500, 'care'), (498, 'feeling'), (504, 'soldiers'), (491, 'clock'), (497, 'past'), (486, 'appeared'), (494, 'blood'), (513, 'beside'), (503, 'talk'), (477, 'carried'), (477, 'raised'), (538, 'later'), (598, 'during'), (483, 'following'), (475, 'soil'), (503, 'hold'), (502, 'evidently'), (482, 'peace'), (468, 'corner'), (484, 'late'), (514, 'really'), (472, 'return'), (467, 'line'), (464, 'horses'), (463, 'arm'), (468, 're'), (485, 'strange'), (466, 'beautiful'), (459, 'fellow'), (463, 'free'), (464, 'live'), (476, 'forward'), (456, 'business'), (828, 'd'), (463, 'read'), (535, 'several'), (453, 'thousand'), (459, 'deep'), (452, 'drew'), (458, 'run'), (451, 'else'), (461, 'tree'), (447, 'kind'), (458, 'summer'), (444, 'position'), (442, 'ordered'), (1033, 'princess'), (446, 'reason'), (447, 'standing'), (438, 'reached'), (446, 'third'), (2053, 'prince'), (454, 'silence'), (451, 'women'), (443, 'across'), (433, 'grown'), (452, 'bring'), (445, 'strong'), (427, 'doing'), (431, 'human'), (429, 'manner'), (427, 'sight'), (430, 'sitting'), (437, 'chief'), (433, 'heavy'), (448, 'believe'), (459, 'six'), (460, 'immediately'), (426, 'foot'), (421, 'doubt'), (428, 'low'), (428, 'comes'), (419, 'least'), (418, 'expression'), (418, 'person'), (469, 'therefore'), (422, 'truth'), (435, 'friends'), (424, 'thee'), (416, 'wounded'), (415, 'cause'), (413, 'family'), (412, 'meet'), (434, 'sea'), (411, 'tried'), (573, 'perhaps'), (425, 'bad'), (483, 'sir'), (411, 'feel'), (420, 'hard'), (405, 'struck'), (404, 'wished'), (508, 'nature'), (431, 'seeing'), (401, 'strength'), (1470, 'm'), (421, 'pass'), (396, 'sun'), (416, 'call'), (403, 'news'), (401, 'wood'), (396, 'seems'), (415, 'ten'), (389, 'troops'), (388, 'train'), (394, 'sure'), (467, 'thy'), (384, 'stopped'), (420, 'gold'), (383, 'form'), (384, 'moved'), (381, 'enemy'), (383, 'bondes'), (379, 'wind'), (379, 'arrived'), (376, 'closed'), (375, 'soldier'), (377, 'sword'), (374, 'mouth'), (424, 'neither'), (402, 'state'), (373, 'die'), (372, 'means'), (371, 'crowd'), (420, 'sister'), (460, 'although'), (420, 'lady'), (398, 'outside'), (368, 'exclaimed'), (402, 'impossible'), (496, 'countess'), (375, 'answer'), (378, 'service'), (368, 'silent'), (366, 'understood'), (365, 'action'), (364, 'different'), (370, 'leaves'), (367, 'afraid'), (374, 'turning'), (360, 'sides'), (366, 'clear'), (359, 'movement'), (360, 'caught'), (372, 'common'), (358, 'account'), (357, 'knows'), (356, 'shouted'), (359, 'talking'), (370, 'law'), (358, 'presence'), (355, 'waiting'), (360, 'attention'), (354, 'broken'), (379, 'beginning'), (363, 'blue'), (351, 'eye'), (348, 'single'), (351, 'boy'), (352, 'big'), (351, 'remain'), (346, 'rode'), (350, 'hope'), (398, 'remember'), (343, 'steps'), (357, 'usually'), (343, 'covered'), (385, 'doctor'), (341, 'minutes'), (343, 'pale'), (338, 'lips'), (339, 'lived'), (362, 'kings'), (339, 'led'), (336, 'hours'), (342, 'stone'), (338, 'conversation'), (335, 'grow'), (336, 'thinking'), (344, 'according'), (334, 'quickly'), (331, 'desire'), (343, 'show'), (357, 'plant'), (332, 'seized'), (331, 'living'), (327, 'noticed'), (369, 'afterwards'), (334, 'joy'), (333, 'speaking'), (341, 'won'), (357, 'hardly'), (324, 'threw'), (1324, 'yes'), (323, 'coat'), (323, 'grew'), (329, 'makes'), (348, 'police'), (325, 'paper'), (322, 'seem'), (324, 'carriage'), (321, 'duty'), (325, 'age'), (334, 'field'), (321, 'loved'), (338, 'middle'), (324, 'pleasure'), (462, 'north'), (346, 'beneath'), (317, 'neck'), (318, 'glance'), (316, 'latter'), (318, 'sailed'), (319, 'watch'), (338, 'toward'), (321, 'commander'), (313, 'purpose'), (312, 'floor'), (315, 'top'), (309, 'spot'), (309, 'asleep'), (308, 'effect'), (307, 'fallen'), (314, 'follow'), (357, 'master'), (305, 'places'), (305, 'planted'), (304, 'distance'), (309, 'forest'), (305, 'reply'), (330, 'wild'), (304, 'glass'), (307, 'darkness'), (308, 'passing'), (331, 'sons'), (309, 'tears'), (304, 'drawing'), (303, 'eat'), (307, 'except'), (317, 'number'), (299, 'sky'), (304, 'straight'), (300, 'attack'), (298, 'fixed'), (301, 'married'), (308, 'orders'), (297, 'ago'), (307, 'rich'), (304, 'stand'), (297, 'usual'), (298, 'died'), (300, 'dinner'), (301, 'fresh'), (299, 'filled'), (312, 'river'), (297, 'fast'), (299, 'ill'), (294, 'barricade'), (295, 'francs'), (340, 'indeed'), (293, 'fight'), (295, 'officers'), (291, 'allowed'), (299, 'pay'), (295, 'pretty'), (290, 'tone'), (292, 'cry'), (289, 'subject'), (319, 'church'), (480, 'la'), (295, 'thin'), (293, 'evil'), (315, 'nearly'), (287, 'shoulders'), (291, 'step'), (310, 'twenty'), (291, 'houses'), (288, 'box'), (284, 'formed'), (291, 'happiness'), (285, 'anyone'), (289, 'change'), (283, 'listened'), (281, 'bottom'), (282, 'forth'), (300, 'iron'), (285, 'piece'), (281, 'appearance'), (284, 'faces'), (310, 'history'), (287, 'kingdom'), (285, 'thoughts'), (345, 'wait'), (279, 'direction'), (281, 'handsome'), (279, 'replies'), (279, 'village'), (289, 'enter'), (281, 'former'), (278, 'mean'), (278, 'repeated'), (278, 'week'), (303, 'beyond'), (280, 'danger'), (275, 'instant'), (277, 'lying'), (313, 'none'), (277, 'particularly'), (278, 'smoke'), (275, 'trouble'), (275, 'walked'), (289, 'green'), (276, 'regiment'), (310, 'society'), (343, 'certainly'), (297, 'company'), (283, 'kill'), (271, 'merely'), (271, 'proceeded'), (271, 'bit'), (284, 'mass'), (277, 'bear'), (272, 'further'), (270, 'prepared'), (293, 'seven'), (296, 'journey'), (272, 'leaving'), (272, 'walk'), (266, 'bent'), (269, 'snow'), (266, 'wide'), (280, 'try'), (269, 'view'), (269, 'growing'), (265, 'holding'), (263, 'resumed'), (263, 'smiled'), (275, 'story'), (264, 'dry'), (265, 'getting'), (263, 'angry'), (260, 'appear'), (260, 'kinds'), (259, 'ourselves'), (273, 'apart'), (265, 'ought'), (263, 'roots'), (260, 'showed'), (268, 'begin'), (257, 'important'), (258, 'legs'), (256, 'simple'), (258, 'cast'), (256, 'effort'), (255, 'started'), (262, 'carry'), (260, 'especially'), (274, 'below'), (274, 'castle'), (256, 'fled'), (253, 'clothes'), (251, 'paid'), (254, 'heads'), (256, 'running'), (253, 'drawn'), (250, 'seated'), (253, 'slowly'), (265, 'varieties'), (251, 'events'), (248, 'hat'), (247, 'opinion'), (248, 'pleased'), (250, 'trying'), (246, 'caused'), (251, 'drove'), (248, 'expected'), (249, 'escape'), (247, 'giving'), (244, 'chair'), (244, 'months'), (267, 'probably'), (248, 'victory'), (249, 'glad'), (244, 'greater'), (255, 'seed'), (243, 'easy'), (256, 'meeting'), (245, 'real'), (243, 'smiling'), (360, 'south'), (244, 'letters'), (262, 'sweet'), (269, 'yellow'), (245, 'bright'), (254, 'chance'), (241, 'difficult'), (240, 'inches'), (243, 'wine'), (239, 'pocket'), (242, 'warm'), (241, 'written'), (245, 'post'), (239, 'serious'), (240, 'simply'), (240, 'teeth'), (239, 'wrong'), (242, 'act'), (237, 'condition'), (278, 'everyone'), (237, 'gazed'), (280, 'le'), (238, 'lines'), (238, 'quarter'), (249, 'various'), (238, 'voices'), (238, 'sad'), (242, 'study'), (280, 'court'), (234, 'disappeared'), (238, 'drink'), (236, 'laugh'), (257, 'brothers'), (231, 'ft'), (271, 'please'), (232, 'shown'), (232, 'spite'), (231, 'bound'), (252, 'city'), (232, 'finished'), (231, 'habit'), (231, 'plain'), (236, 'public'), (230, 'remarked'), (230, 'broke'), (229, 'interest'), (229, 'command'), (230, 'dressed'), (230, 'goes'), (233, 'questions'), (231, 'rain'), (228, 'considered'), (240, 'tall'), (227, 'frightened'), (228, 'future'), (229, 'moving'), (230, 'streets'), (228, 'weather'), (279, 'whatever'), (243, 'excellent'), (226, 'forms'), (225, 'parts'), (262, 'art'), (233, 'save'), (228, 'space'), (230, 'lie'), (246, 'brave'), (236, 'eight'), (226, 'gentleman'), (229, 'unknown'), (222, 'breath'), (224, 'lies'), (222, 'thrown'), (310, 'book'), (221, 'settled'), (222, 'touched'), (221, 'girls'), (221, 'grave'), (219, 'minute'), (233, 'bridge'), (219, 'deal'), (220, 'move'), (222, 'surprise'), (220, 'wolf'), (217, 'advanced'), (222, 'contrary'), (220, 'dress'), (217, 'affair'), (216, 'changed'), (218, 'flew'), (217, 'hole'), (219, 'looks'), (233, 'send'), (215, 'talked'), (229, 'allow'), (216, 'aside'), (225, 'blow'), (222, 'calm'), (233, 'honor'), (219, 'plan'), (213, 'remembered'), (217, 'sign'), (236, 'sit'), (215, 'spread'), (223, 'dream'), (212, 'month'), (216, 'planting'), (224, 'speech'), (213, 'surface'), (214, 'affairs'), (213, 'season'), (217, 'shadow'), (216, 'dog'), (211, 'walls'), (209, 'glanced'), (218, 'lower'), (210, 'matters'), (210, 'occupied'), (209, 'offered'), (212, 'play'), (209, 'presented'), (211, 'result'), (210, 'understanding'), (217, 'hall'), (213, 'peasant'), (209, 'property'), (208, 'sprang'), (226, 'stay'), (209, 'easily'), (220, 'flight'), (216, 'knowing'), (207, 'laughed'), (211, 'shot'), (209, 'bread'), (209, 'sown'), (207, 'burst'), (211, 'gate'), (208, 'rushed'), (205, 'spoken'), (203, 'desired'), (204, 'forced'), (207, 'pity'), (206, 'burning'), (216, 'station'), (202, 'wrote'), (204, 'crime'), (201, 'windows'), (364, 'besides'), (202, 'rapidly'), (202, 'seat'), (205, 'secret'), (203, 'terror'), (200, 'appears'), (200, 'laughing'), (199, 'sense'), (230, 'to-day'), (210, 'youth'), (198, 'greatest'), (203, 'message'), (198, 'occurred'), (198, 'perceived'), (215, 'quick'), (198, 'shook'), (203, 'start'), (205, 'bird'), (197, 'knees'), (198, 'papers'), (199, 'quiet'), (197, 'removed'), (199, 'special'), (200, 'advance'), (197, 'begun'), (198, 'empty'), (200, 'fly'), (214, 'marriage'), (209, 'shut'), (209, 'twelve'), (197, 'visible'), (212, 'write'), (202, 'board'), (288, 'east'), (199, 'respect'), (195, 'sake'), (196, 'dying'), (213, 'everywhere'), (231, 'figure'), (197, 'fleet'), (234, 'heaven'), (195, 'perfectly'), (193, 'recognized'), (196, 'silver'), (198, 'break'), (244, 'cross'), (198, 'farther'), (194, 'grass'), (198, 'spirit'), (192, 'waited'), (194, 'immense'), (193, 'observed'), (190, 'gathered'), (252, 'listen'), (191, 'promised'), (205, 'trench'), (191, 'difficulty'), (205, 'fate'), (196, 'useful'), (199, 'foliage'), (188, 'kissed'), (188, 'length'), (189, 'noise'), (188, 'relations'), (188, 'required'), (225, 'stop'), (220, 'thick'), (189, 'ball'), (187, 'moments'), (197, 'ring'), (197, 'thirty'), (186, 'approached'), (186, 'happen'), (186, 'paused'), (186, 'pointed'), (186, 'related'), (186, 'served'), (187, 'shoulder'), (192, 'tender'), (189, 'forces'), (187, 'lives'), (189, 'priest'), (193, 'beauty'), (184, 'ears'), (184, 'experienced'), (188, 'midst'), (194, 'persons'), (184, 'bloom'), (192, 'charming'), (184, 'ended'), (183, 'hot'), (187, 'inside'), (184, 'occasion'), (183, 'ones'), (187, 'opening'), (185, 'pressed'), (191, 'prisoner'), (195, 'search'), (192, 'ancient'), (184, 'natural'), (183, 'object'), (182, 'reach'), (182, 'bare'), (182, 'doors'), (181, 'fit'), (240, 'guard'), (207, 'instead'), (197, 'justice'), (183, 'proper'), (182, 'stones'), (183, 'visit'), (186, 'agreed'), (189, 'becomes'), (186, 'feast'), (180, 'gloomy'), (183, 'marry'), (182, 'prevent'), (180, 'produced'), (185, 'worse'), (180, 'worth'), (185, 'clearly'), (182, 'enormous'), (180, 'friendship'), (180, 'notice'), (179, 'slept'), (180, 'walking'), (180, 'wound'), (178, 'bore'), (180, 'falling'), (180, 'particular'), (192, 'someone'), (178, 'species'), (207, 'yard'), (178, 'cap'), (262, 'march'), (179, 'melancholy'), (181, 'mysterious'), (180, 'pain'), (180, 'suffering'), (176, 'gentle'), (201, 'hill'), (176, 'knife'), (177, 'nose'), (180, 'regard'), (181, 'adjutant'), (178, 'food'), (180, 'forget'), (176, 'group'), (175, 'inquired'), (317, 'l'), (176, 'prisoners'), (212, 'ye'), (174, 'ceased'), (183, 'chamber'), (234, 'holy'), (190, 'military'), (175, 'race'), (176, 'report'), (174, 'rows'), (178, 'sharp'), (178, 'weeks'), (176, 'advice'), (173, 'evident'), (177, 'mine'), (173, 'rule'), (178, 'broad'), (173, 'composed'), (174, 'ideas'), (172, 'likely'), (172, 'meaning'), (172, 'memory'), (184, 'note'), (203, 'to-morrow'), (171, 'alive'), (185, 'amid'), (172, 'asking'), (173, 'complete'), (175, 'entirely'), (171, 'fingers'), (172, 'learned'), (174, 'shadows'), (171, 'throat'), (209, 'golden'), (172, 'growth'), (177, 'imagine'), (178, 'ladies'), (171, 'lifted'), (170, 'meant'), (171, 'unable'), (170, 'uttered'), (169, 'breast'), (173, 'horror'), (169, 'motionless'), (173, 'generally'), (168, 'guns'), (173, 'haste'), (170, 'key'), (173, 'laws'), (177, 'opposite'), (168, 'party'), (173, 'straw'), (170, 'becoming'), (169, 'candle'), (167, 'character'), (167, 'decided'), (179, 'fifteen'), (167, 'obliged'), (168, 'surprised'), (168, 'touch'), (170, 'autumn'), (239, 'captain'), (170, 'freedom'), (170, 'passage'), (175, 'staff'), (167, 'telling'), (165, 'belonged'), (166, 'branches'), (168, 'carefully'), (187, 'formerly'), (164, 'arranged'), (166, 'conditions'), (166, 'lose'), (164, 'mentioned'), (166, 'reader'), (168, 'satisfied'), (169, 'stout'), (163, 'advantage'), (170, 'despair'), (188, 'everybody'), (165, 'express'), (170, 'fruit'), (163, 'pulled'), (172, 'suppose'), (167, 'takes'), (163, 'vessel'), (163, 'concealed'), (167, 'departure'), (167, 'district'), (162, 'finger'), (162, 'interrupted'), (172, 'throw'), (161, 'crop'), (161, 'crossed'), (164, 'des'), (166, 'drive'), (166, 'entering'), (162, 'forgotten'), (162, 'quarters'), (163, 'buried'), (161, 'frightful'), (165, 'receive'), (160, 'shore'), (160, 'spent'), (160, 'sufficient'), (166, 'absolutely'), (162, 'er'), (159, 'lighted'), (163, 'rise'), (163, 'boots'), (175, 'devil'), (158, 'expressed'), (167, 'fair'), (158, 'fault'), (158, 'handed'), (160, 'loss'), (160, 'manure'), (160, 'narrow'), (158, 'path'), (160, 'peasants'), (158, 'sought'), (158, 'sudden'), (158, 'built'), (163, 'double'), (159, 'gray'), (163, 'health'), (163, 'huge'), (157, 'liked'), (159, 'mud'), (157, 'edge'), (225, 'grand'), (156, 'joined'), (157, 'possession'), (158, 'profound'), (155, 'beheld'), (209, 'colonel'), (158, 'grandfather'), (160, 'row'), (157, 'saved'), (160, 'seek'), (155, 'sorts'), (156, 'stupid'), (161, 'du'), (156, 'false'), (157, 'fashion'), (158, 'firm'), (154, 'fought'), (155, 'knowledge'), (160, 'lead'), (154, 'pieces'), (164, 'social'), (156, 'thrust'), (154, 'watched'), (154, 'wore'), (168, 'building'), (154, 'chiefs'), (167, 'clever'), (193, 'consider'), (155, 'depths'), (156, 'faith'), (153, 'intended'), (154, 'luck'), (154, 'putting'), (192, 'square'), (153, 'weak'), (153, 'whispered'), (155, 'escaped'), (152, 'event'), (162, 'flat'), (153, 'mad'), (174, 'murder'), (157, 'nearer'), (153, 'pushed'), (154, 'remains'), (153, 'stranger'), (152, 'uniform'), (155, 'beds'), (158, 'fortune'), (174, 'government'), (156, 'hearing'), (173, 'progress'), (153, 'rooms'), (150, 'appointed'), (150, 'boxes'), (150, 'dropped'), (151, 'lawn'), (162, 'liberty'), (153, 'merry'), (157, 'promise'), (150, 'shouting'), (153, 'surrounded'), (150, 'borne'), (151, 'driver'), (150, 'existence'), (151, 'facts'), (150, 'gesture'), (152, 'hung'), (149, 'needed'), (149, 'peculiar'), (149, 'quietly'), (157, 'song'), (150, 'succeeded'), (149, 'thoroughly'), (149, 'vague'), (149, 'aim'), (155, 'cat'), (148, 'explain'), (160, 'kindly'), (148, 'necessity'), (148, 'proved'), (149, 'worthy'), (149, 'confused'), (251, 'queen'), (147, 'rising'), (147, 'roof'), (151, 'somewhat'), (148, 'vast'), (148, 'address'), (146, 'addressed'), (147, 'cart'), (146, 'explained'), (146, 'gained'), (146, 'horrible'), (161, 'sewer'), (175, 'yesterday'), (147, 'cannon'), (145, 'creature'), (145, 'expect'), (148, 'laughter'), (146, 'powerful'), (159, 'reading'), (149, 'souls'), (146, 'century'), (149, 'loud'), (144, 'sang'), (145, 'servants'), (167, 'twice'), (144, 'accompanied'), (145, 'armed'), (143, 'bench'), (154, 'fifty'), (144, 'gazing'), (145, 'keeping'), (147, 'listening'), (146, 'passion'), (144, 'results'), (149, 'severe'), (142, 'assembled'), (162, 'blind'), (149, 'bold'), (142, 'coffin'), (143, 'offer'), (142, 'safe'), (155, 'seeds'), (142, 'shock'), (143, 'soft'), (157, 'unless'), (142, 'fields'), (143, 'mingled'), (141, 'possessed'), (141, 'servant'), (142, 'clouds'), (155, 'didn'), (141, 'lad'), (141, 'leg'), (140, 'lot'), (140, 'named'), (143, 'pleasant'), (140, 'stepped'), (143, 'arrival'), (140, 'badly'), (140, 'carrying'), (141, 'cases'), (139, 'determined'), (161, 'hardy'), (151, 'otherwise'), (141, 'situation'), (139, 'treated'), (140, 'accept'), (138, 'cloak'), (139, 'conscious'), (156, 'convent'), (150, 'cover'), (139, 'dust'), (139, 'ordinary'), (138, 'picked'), (139, 'ranks'), (138, 'relation'), (138, 'shoes'), (139, 'wheels'), (138, 'bowed'), (140, 'conscience'), (138, 'names'), (137, 'played'), (138, 'violent'), (137, 'watching'), (137, 'circumstances'), (145, 'draw'), (138, 'experience'), (136, 'friendly'), (137, 'greatly'), (136, 'singing'), (143, 'success'), (139, 'birds'), (152, 'courage'), (138, 'deserted'), (135, 'ear'), (136, 'harm'), (143, 'nine'), (135, 'paces'), (138, 'splendid'), (137, 'trembling'), (134, 'aid'), (136, 'brilliant'), (138, 'daylight'), (134, 'distant'), (135, 'engine'), (138, 'equal'), (139, 'gently'), (136, 'maid'), (135, 'raise'), (138, 'returning'), (136, 'setting'), (141, 'somewhere'), (136, 'sorry'), (134, 'suffer'), (139, 'wet'), (133, 'activity'), (137, 'border'), (139, 'catch'), (138, 'dare'), (133, 'engaged'), (158, 'expedition'), (134, 'increased'), (139, 'learn'), (154, 'nobody'), (135, 'prove'), (136, 'sounds'), (133, 'suffered'), (137, 'supper'), (145, 'to-night'), (133, 'ways'), (132, 'due'), (134, 'dull'), (154, 'gentlemen'), (138, 'loose'), (132, 'retreat'), (138, 'sand'), (133, 'summoned'), (131, 'fully'), (134, 'gives'), (132, 'points'), (134, 'trust'), (152, 'add'), (134, 'admit'), (130, 'cloth'), (130, 'dared'), (178, 'dwarf'), (132, 'gaze'), (131, 'serve'), (130, 'size'), (130, 'tongue'), (129, 'actions'), (130, 'anxious'), (130, 'cloud'), (130, 'couple'), (129, 'demanded'), (129, 'details'), (129, 'directed'), (129, 'happens'), (129, 'opportunity'), (129, 'refused'), (130, 'writing'), (128, 'beings'), (132, 'campaign'), (133, 'dawn'), (128, 'ease'), (146, 'exactly'), (131, 'glory'), (128, 'main'), (128, 'recognize'), (129, 'sick'), (128, 'abandoned'), (128, 'circle'), (127, 'distinguished'), (132, 'extraordinary'), (127, 'fond'), (130, 'higher'), (128, 'level'), (127, 'shade'), (128, 'sous'), (126, 'approaching'), (425, 'bishop'), (127, 'books'), (126, 'brain'), (126, 'cellar'), (126, 'chest'), (128, 'chosen'), (127, 'completely'), (127, 'dreadful'), (129, 'driven'), (131, 'excellency'), (127, 'flesh'), (126, 'galleys'), (126, 'gun'), (126, 'murmured'), (128, 'singular'), (126, 'slight'), (129, 'anger'), (128, 'familiar'), (125, 'halted'), (126, 'historians'), (127, 'regular'), (125, 'separated'), (125, 'sleeping'), (127, 'storm'), (125, 'vessels'), (159, 'finally'), (125, 'heat'), (125, 'hideous'), (126, 'honest'), (124, 'protection'), (138, 'roses'), (134, 'skald'), (123, 'accepted'), (124, 'anxiety'), (123, 'corpse'), (134, 'farm'), (125, 'grief'), (128, 'height'), (132, 'misery'), (128, 'shield'), (126, 'stands'), (123, 'task'), (125, 'torn'), (124, 'cavalry'), (124, 'counsel'), (122, 'feared'), (122, 'forehead'), (122, 'gloom'), (123, 'heap'), (126, 'honour'), (123, 'material'), (126, 'perfect'), (126, 'private'), (123, 'sail'), (138, 'whence'), (127, 'directly'), (122, 'firing'), (127, 'flower'), (124, 'noble'), (125, 'office'), (124, 'personal'), (122, 'remark'), (205, 'west'), (130, 'avoid'), (121, 'believed'), (126, 'bow'), (135, 'bulbs'), (122, 'charge'), (122, 'cleared'), (124, 'drop'), (128, 'fourth'), (123, 'goods'), (131, 'instantly'), (121, 'pair'), (120, 'shed'), (122, 'speed'), (121, 'stretched'), (121, 'tired'), (123, 'virtue'), (120, 'cheeks'), (120, 'destroyed'), (119, 'direct'), (120, 'entrance'), (120, 'prison'), (123, 'pure'), (119, 'rage'), (120, 'resolved'), (123, 'wedding'), (125, 'wonderful'), (124, 'absolute'), (119, 'attitude'), (120, 'beast'), (118, 'dangerous'), (120, 'deeply'), (118, 'descended'), (123, 'dogs'), (118, 'established'), (123, 'finding'), (119, 'gay'), (118, 'masses'), (119, 'merchant'), (174, 'pray'), (120, 'sorrow'), (120, 'vain'), (117, 'begged'), (119, 'comrades'), (122, 'cutting'), (117, 'discovered'), (117, 'examined'), (118, 'join'), (121, 'leading'), (117, 'pause'), (119, 'shows'), (118, 'support'), (117, 'turns'), (119, 'wants'), (119, 'wearing'), (117, 'accustomed'), (118, 'continually'), (116, 'existed'), (123, 'hast'), (116, 'method'), (146, 'whilst'), (117, 'beat'), (121, 'choose'), (115, 'corridor'), (120, 'glancing'), (128, 'kiss'), (116, 'lit'), (117, 'nice'), (116, 'porter'), (116, 'rapid'), (129, 'royal'), (115, 'value'), (115, 'vanished'), (114, 'animal'), (116, 'curiosity'), (117, 'fighting'), (117, 'generals'), (114, 'hurt'), (114, 'oath'), (117, 'rear'), (114, 'stared'), (118, 'stars'), (116, 'cook'), (113, 'guests'), (114, 'hanging'), (115, 'hastily'), (113, 'importance'), (143, 'isn'), (113, 'jumped'), (114, 'miles'), (114, 'mist'), (115, 'pointing'), (115, 'scene'), (113, 'stayed'), (117, 'tea'), (130, 'tomorrow'), (113, 'variety'), (113, 'wooden'), (115, 'worn'), (113, 'attacked'), (114, 'bodies'), (113, 'breathing'), (114, 'center'), (113, 'committed'), (115, 'dirty'), (117, 'frequently'), (113, 'highest'), (156, 'mon'), (130, 'scarcely'), (113, 'sees'), (115, 'slightly'), (112, 'sum'), (114, 'unhappy'), (137, 'bank'), (111, 'brow'), (112, 'bushes'), (112, 'depth'), (113, 'difference'), (111, 'dignity'), (111, 'hastened'), (111, 'hidden'), (118, 'hurry'), (113, 'moon'), (111, 'playing'), (111, 'porch'), (112, 'tells'), (114, 'upper'), (112, 'weary'), (110, 'approach'), (112, 'attempt'), (111, 'causes'), (111, 'convinced'), (111, 'epoch'), (110, 'mistake'), (110, 'resolution'), (110, 'rope'), (113, 'similar'), (110, 'skin'), (115, 'thence'), (111, 'troubled'), (110, 'weapons'), (110, 'confidence'), (114, 'desirable'), (111, 'game'), (113, 'infantry'), (109, 'innocent'), (112, 'lendermen'), (110, 'linen'), (109, 'muttered'), (109, 'sofa'), (110, 'burned'), (108, 'convict'), (108, 'declared'), (110, 'drunk'), (108, 'entire'), (109, 'exist'), (110, 'influence'), (109, 'lamp'), (108, 'movements'), (108, 'previous'), (115, 'proceed'), (108, 'rendered'), (112, 'thither'), (107, 'ate'), (107, 'aware'), (107, 'boat'), (115, 'clean'), (119, 'fancy'), (107, 'flank'), (107, 'gain'), (110, 'hussars'), (107, 'hut'), (109, 'popular'), (111, 'agreement'), (107, 'awoke'), (107, 'band'), (106, 'branch'), (107, 'collected'), (107, 'conceal'), (107, 'confusion'), (107, 'frame'), (106, 'galloped'), (177, 'hills'), (106, 'impression'), (106, 'pavement'), (106, 'produce'), (111, 'raising'), (111, 'shouts'), (105, 'attached'), (109, 'beard'), (106, 'beg'), (106, 'blame'), (105, 'closely'), (106, 'driving'), (105, 'example'), (106, 'flame'), (106, 'frost'), (116, 'meantime'), (105, 'pipe'), (105, 'rolled'), (108, 'sacrifice'), (106, 'share'), (106, 'shining'), (106, 'terrified'), (112, 'tomb'), (117, 'yours'), (105, 'breaking'), (106, 'defend'), (105, 'delicate'), (105, 'eastward'), (112, 'erect'), (116, 'forty'), (106, 'hollow'), (105, 'interesting'), (105, 'larger'), (105, 'mere'), (107, 'mystery'), (110, 'provided'), (104, 'satisfaction'), (104, 'shudder'), (109, 'abruptly'), (104, 'absence'), (104, 'aloud'), (103, 'angrily'), (103, 'bearing'), (111, 'born'), (104, 'busy'), (103, 'companion'), (103, 'connection'), (103, 'covering'), (105, 'cries'), (103, 'disease'), (108, 'divine'), (104, 'intelligence'), (107, 'judge'), (105, 'leaning'), (104, 'pots'), (103, 'reality'), (103, 'remaining'), (105, 'slow'), (106, 'artillery'), (102, 'assistant'), (105, 'bell'), (105, 'carriages'), (104, 'coast'), (106, 'curious'), (104, 'fatigue'), (102, 'freely'), (103, 'hearts'), (103, 'kitchen'), (102, 'managed'), (103, 'reasons'), (103, 'ride'), (102, 'ruled'), (102, 'silently'), (112, 'sovereign'), (102, 'struggle'), (142, 'thanks'), (108, 'universal'), (112, 'wise'), (105, 'begins'), (102, 'considerable'), (106, 'destiny'), (101, 'distinctly'), (101, 'formidable'), (103, 'gardener'), (110, 'grey'), (109, 'inn'), (101, 'locked'), (114, 'nonsense'), (101, 'plunged'), (104, 'showing'), (101, 'smell'), (102, 'useless'), (101, 'worked'), (101, 'absorbed'), (100, 'agree'), (102, 'astonished'), (101, 'authority'), (105, 'bourgeois'), (101, 'chain'), (102, 'crossing'), (101, 'divided'), (100, 'eaten'), (116, 'elder'), (101, 'ends'), (108, 'gradually'), (102, 'instinct'), (100, 'mounted'), (100, 'pistol'), (102, 'pot'), (103, 'pride'), (100, 'slipped'), (100, 'station-master'), (182, 'thank'), (100, 'wounds'), (22996, 'i')]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Tokenize texts -------------------------------\n",
    "# Load tokenized versions of texts if you have already generated it\n",
    "# Otherwise, create it and save it\n",
    "if os.path.isfile(PATH_GENERATED + \"words_train.pt\"):\n",
    "    words_train = torch.load(PATH_GENERATED + \"words_train.pt\")\n",
    "    words_val   = torch.load(PATH_GENERATED + \"words_val.pt\")\n",
    "    words_test  = torch.load(PATH_GENERATED + \"words_test.pt\")\n",
    "else:\n",
    "    # Get lists of strings, one for each line in each .txt files in 'datapath' \n",
    "    lines_books_train = read_files('./data_train/')\n",
    "    lines_books_val   = read_files('./data_val/')\n",
    "    lines_books_test  = read_files('./data_test/')\n",
    "\n",
    "    # List of words contained in the dataset\n",
    "    words_train = tokenize(lines_books_train)\n",
    "    words_val   = tokenize(lines_books_val)\n",
    "    words_test  = tokenize(lines_books_test)\n",
    "    \n",
    "    torch.save(words_train, PATH_GENERATED + \"words_train.pt\")\n",
    "    torch.save(words_val, PATH_GENERATED + \"words_val.pt\")\n",
    "    torch.save(words_test, PATH_GENERATED + \"words_test.pt\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Create vocabulary ----------------------------\n",
    "VOCAB_FNAME = \"vocabulary.pt\"\n",
    "# Load vocabulary if you have already generated it\n",
    "# Otherwise, create it and save it\n",
    "if os.path.isfile(PATH_GENERATED + VOCAB_FNAME):\n",
    "    vocab = torch.load(PATH_GENERATED + VOCAB_FNAME)\n",
    "else:\n",
    "    # Create vocabulary based on the words in the training dataset\n",
    "    vocab = create_vocabulary(lines_books_train, min_freq=MIN_FREQ)\n",
    "    torch.save(vocab, PATH_GENERATED + VOCAB_FNAME)\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------------ Quick analysis ------------------------------\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(\"Total number of words in the training dataset:     \", len(words_train))\n",
    "print(\"Total number of words in the validation dataset:   \", len(words_val))\n",
    "print(\"Total number of words in the test dataset:         \", len(words_test))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(words_train)))\n",
    "print(\"Number of distinct words kept (vocabulary size):   \", VOCAB_SIZE)\n",
    "\n",
    "freqs = count_freqs(words_train, vocab)\n",
    "print(\"occurences:\\n\", [(f.item(), w) for (f, w) in zip(freqs, vocab.lookup_tokens(range(VOCAB_SIZE)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Define targets ------------------------------\n",
    "def compute_label(w):\n",
    "    \"\"\"\n",
    "    helper function to define MAP_TARGET\n",
    "    \n",
    "    - 0 = 'unknown word'\n",
    "    - 1 = 'punctuation' (i.e. the '<unk>' token)\n",
    "    - 2 = 'is an actual word'\n",
    "    \"\"\"\n",
    "    if w in ['<unk>']:\n",
    "        return 0\n",
    "    elif w in [',', '.', '(', ')', '?', '!']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# true labels for this task:\n",
    "MAP_TARGET = {\n",
    "    vocab[w]: compute_label(w) for w in vocab.lookup_tokens(range(VOCAB_SIZE))\n",
    "}\n",
    "\n",
    "# context size for this task \n",
    "CONTEXT_SIZE = 3\n",
    "\n",
    "# ---------------- Define context / target pairs -----------------------\n",
    "def create_dataset(\n",
    "    text, vocab, \n",
    "    context_size=CONTEXT_SIZE, map_target=MAP_TARGET\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset of context / target pairs from a text\n",
    "    \"\"\"\n",
    "    \n",
    "    n_text = len(text)\n",
    "    n_vocab = len(vocab)\n",
    "    \n",
    "    # Change labels if only a few target are kept, otherwise, each word is\n",
    "    # associated with its index in the vocabulary\n",
    "    if map_target is None:\n",
    "        map_target = {i:i for i in range(n_vocab)}\n",
    "    \n",
    "    # Transform the text as a list of integers.\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    # Start constructing the context / target pairs...\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(n_text - context_size):\n",
    "        \n",
    "        # Word used to define target\n",
    "        t = txt[i + context_size]\n",
    "        \n",
    "        # Context before the target\n",
    "        c = txt[i:i + context_size]\n",
    "        \n",
    "        targets.append(map_target[t])\n",
    "        contexts.append(torch.tensor(c))\n",
    "            \n",
    "    # contexts of shape (N_dataset, context_size)\n",
    "    # targets of shape  (N_dataset)\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    # Create a pytorch dataset out of these context / target pairs\n",
    "    return TensorDataset(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it\n",
    "    \"\"\"\n",
    "    # If already generated\n",
    "    if os.path.isfile(PATH_GENERATED + fname):\n",
    "        dataset = torch.load(PATH_GENERATED + fname)\n",
    "    else:\n",
    "        # Create context / target dataset based on the list of strings\n",
    "        dataset = create_dataset(words, vocab)\n",
    "        torch.save(dataset, PATH_GENERATED + fname)\n",
    "    return dataset\n",
    "\n",
    "data_train = load_dataset(words_train, vocab, \"data_train.pt\")\n",
    "data_val   = load_dataset(words_val, vocab, \"data_val.pt\")\n",
    "data_test  = load_dataset(words_test, vocab, \"data_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding=None, context_size=CONTEXT_SIZE):\n",
    "        super().__init__()\n",
    "        \n",
    "        (vocab_size, embedding_dim) = embedding.weight.shape\n",
    "        # Instantiate an embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "            \n",
    "        # Regular MLP\n",
    "        self.fc1 = nn.Linear(embedding_dim*context_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (N, context_size) but contains integers which can\n",
    "        # be seen as equivalent to (N, context_size, vocab_size) since one hot\n",
    "        # encoding is used under the hood\n",
    "        out = self.embedding(x)\n",
    "        # out is now of shape (N, context_size, embedding_dim)\n",
    "        \n",
    "        out = F.relu(self.fc1(torch.flatten(out, 1)))\n",
    "        # out is now of shape (N, context_size*embedding_dim)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "# Load the pretrained embedding \n",
    "if os.path.isfile(\"embedding.pt\"):\n",
    "    embedding = torch.load(\"embedding.pt\").to(device=device)\n",
    "else:\n",
    "    raise ValueError(\"Embedding not found at the given location\")\n",
    "\n",
    "MODEL_FNAME = \"model.pt\"\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(data_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(data_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = MyMLP(embedding)\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + MODEL_FNAME):\n",
    "    # Load the trained model\n",
    "    model = torch.load(PATH_GENERATED + MODEL_FNAME)\n",
    "    model.to(device)\n",
    "else:\n",
    "    # Or train the model...\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    n_epochs=30\n",
    "\n",
    "    train(n_epochs, optimizer, model, loss_fn, train_loader)\n",
    "    # ... and save it\n",
    "    torch.save(model.to(device=\"cpu\"), PATH_GENERATED + MODEL_FNAME)\n",
    "\n",
    "acc_train = compute_accuracy(model, train_loader)\n",
    "acc_val = compute_accuracy(model, val_loader)\n",
    "print(\"Training Accuracy:     %.4f\" %acc_train)\n",
    "print(\"Validation Accuracy:   %.4f\" %acc_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
